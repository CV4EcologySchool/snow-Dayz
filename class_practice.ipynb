{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area of Rectangle: 19200 sq units\n"
     ]
    }
   ],
   "source": [
    "class Rectangle:\n",
    "   def __init__(self, length, breadth, unit_cost=0):\n",
    "       self.length = length\n",
    "       self.breadth = breadth\n",
    "       self.unit_cost = unit_cost\n",
    "       self.test = 500\n",
    "   def get_area(self):\n",
    "       return self.length * self.breadth\n",
    "   def calculate_cost(self):\n",
    "       area = self.get_area()\n",
    "       return area * self.unit_cost\n",
    "# breadth = 120 units, length = 160 units, 1 sq unit cost = Rs 2000\n",
    "r = Rectangle(160, 120, 2000)\n",
    "print(\"Area of Rectangle: %s sq units\" % (r.get_area()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_covered = set() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_covered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/cmbreen/code/snow-Dayz/class_practice.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cmbreen/code/snow-Dayz/class_practice.ipynb#ch0000003?line=14'>15</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cmbreen/code/snow-Dayz/class_practice.ipynb#ch0000003?line=15'>16</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cmbreen/code/snow-Dayz/class_practice.ipynb#ch0000003?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cmbreen/code/snow-Dayz/class_practice.ipynb#ch0000003?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m Compose, Resize, ToTensor\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cmbreen/code/snow-Dayz/class_practice.ipynb#ch0000003?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    PyTorch dataset class for COCO-CT-formatted datasets. Note that you could\n",
    "    use the official PyTorch MS-COCO wrappers:\n",
    "    https://pytorch.org/vision/master/generated/torchvision.datasets.CocoDetection.html\n",
    "\n",
    "    We just hack our way through the COCO JSON files here for demonstration\n",
    "    purposes.\n",
    "\n",
    "    See also the MS-COCO format on the official Web page:\n",
    "    https://cocodataset.org/#format-data\n",
    "\n",
    "    2022 Benjamin Kellenberger\n",
    "'''\n",
    "\n",
    "import os\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class CTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, labels, cfg, folder, split='train'):\n",
    "        '''\n",
    "            Constructor. Here, we collect and index the dataset inputs and\n",
    "            labels.\n",
    "        '''\n",
    "        self.data_root = cfg['data_root']\n",
    "        self.split = split\n",
    "        self.folder = folder\n",
    "        self.transform = Compose([              # Transforms. Here's where we could add data augmentation (see Björn's lecture on August 11).\n",
    "            Resize((cfg['image_size'])),        # For now, we just resize the images to the same dimensions...\n",
    "            ToTensor()                          # ...and convert them to torch.Tensor.\n",
    "        ])\n",
    "        \n",
    "        # index data into list\n",
    "        self.data = []\n",
    "\n",
    "        # load annotation file\n",
    "        self.annoPath = os.path.join(\n",
    "            self.data_root, labels) ############# should i set this as an input?? \n",
    "\n",
    "        meta = pd.read_csv(self.annoPath)\n",
    "        # meta = json.load(open(annoPath, 'r'))\n",
    "\n",
    "        #images = dict([[idx, file] for idx, file in enumerate(meta['File'])]) ## do enumerate or do index\n",
    "        #labels = dict([[idx, file] for idx, file in enumerate(meta['Weather'])])\n",
    "\n",
    "        ######### image sort?? \n",
    "\n",
    "        # images = dict([[i['id'], i['file_name']] for i in meta['images']])          # image id to filename lookup\n",
    "        # labels = dict([[c['id'], idx] for idx, c in enumerate(meta['categories'])]) # custom labelclass indices that start at zero\n",
    "        \n",
    "        # # since we're doing classification, we're just taking the first annotation per image and drop the rest\n",
    "        images_covered = set()      # all those images for which we have already assigned a label\n",
    "         \n",
    "        #for anno in meta['Weather']:\n",
    "         #     if (anno != \"Fog\"):\n",
    "        \n",
    "        #       imgID = anno['image_id'] ## i don't have image ID\n",
    "        #       if imgID in images_covered:\n",
    "        #           continue\n",
    "            \n",
    "            #     # append image-label tuple to data\n",
    "            #     imgFileName = images[imgID]\n",
    "            #     label = anno['category_id']\n",
    "            #     labelIndex = labels[label]\n",
    "\n",
    "        meta = meta[meta['Weather'] != 'Fog']\n",
    "        meta = meta.drop_duplicates().reset_index() ## maybe I should keep the original indices??\n",
    "        \n",
    "        #images = meta['File']\n",
    "        #labels = meta['Weather']\n",
    "        for file, weather in meta['File'], meta['Weather']:\n",
    "            imgFileName = file\n",
    "            labelIndex = meta[meta['Weather'] == weather].index\n",
    "            imgID = labelIndex ## they are the same thing in my dataset because I didn't generate a imgID\n",
    "            self.data.append([imgFileName, labelIndex]) ## why label index and not label?\n",
    "            images_covered.add() ## this is kind of irrelevant for my data\n",
    "\n",
    "        #self.data.append([imgFileName, labelIndex])\n",
    "        #images_covered.add(imgID)       # make sure image is only added once to dataset\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "            Returns the length of the dataset.\n",
    "        '''\n",
    "        return len(self.data)\n",
    "\n",
    "    def __shape__(self):\n",
    "        return (self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "            Returns a single data point at given idx.\n",
    "            Here's where we actually load the image.\n",
    "        '''\n",
    "        image_name, label = self.data[idx]              # see line 57 above where we added these two items to the self.data list\n",
    "\n",
    "        # load image\n",
    "        image_path = os.path.join(self.data_root, self.folder, image_name) ## should specify train folder and get image name \n",
    "        img = Image.open(image_path).convert('RGB')     # the \".convert\" makes sure we always get three bands in Red, Green, Blue order\n",
    "\n",
    "        # transform: see lines 31ff above where we define our transformations\n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        return img_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.12.1-cp39-none-macosx_10_9_x86_64.whl (133.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 133.8 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/cmbreen/miniconda3/lib/python3.9/site-packages (from torch) (4.0.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## potential command run \n",
    "CTDataset(labels = 'all_labels_QC.csv', folder= 'train', cfg = 'exp_resnet50_2classes.yaml', split= 'train')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
