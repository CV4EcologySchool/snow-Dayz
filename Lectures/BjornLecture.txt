

Acquiring large labeled datasets is costly 

Issues: 

Generalization with Neural Networks can be brittle

Trained on Maxar satellite imagery 

How to quantify out-of-distribution?
    - Human evaluation 
    - Distance in Euclidean space 
        - Regression 
        - 
    - Distance in feature space

Augmentation aims to convert extrapolation to interpolation
    - data augmentation incrases the size of the train ndata aiming for the test to becoem a subset of the train data. 
    - you have to use your domain knowledge to know what axis you can change 
        - exposure, horizontal flip, gaussian blur, rotational 

Common axes of variation 
- Differning environmental conditions (day, night, fog, snow, rain, haze, lighting shadows)
- RS: atmospheric noise, sun inclination
- A: background noises

Differing sensors
- Im: resolution, aperture, 

Augmentations incoroporate domain knowledge
Goal: introduce domain knowledge and synthetic variation that does not change the label (invariance) or changes the label in a known way (equivariance)

We would still expect Snoop Dog to be snoop dog no matter the hat he is wearing!

How do we implement? There are libraries available! 
- Flipping, 
- Random Crop and Resize 

For weather: 
Do's: 
- Crop a tiny square
- increase brightness
- Flipping 
- day vs night 
- convert everything to a grey scale
Don'ts: 
- introducing weather (overlay clouds or rain) --> use random weather! built-in in python
- noise / guassian, drop out noise (tiny black values)

Adversarial noise - if you change a pixel it can go from a beaver to a panda and make our model 
-

Mixup//CutMix
    take two images 


Define an augmentation pipeline 
- 

Look up at albumentaitons!! 

Apply distortions in dataloader; not in storage 

Best-practices loads augmentation parameters from config.yaml 
- that way you can play 

Sounds great but still in research stage 
- train generative vision model, e.g. GAN on data and sample

Adding syntehtic data does work, but it does require a lot of effort and money and multiple simulation data 

When to stop augmentigng and label more data?
- stop if augmentation doesn't majorly improve evaluation results
- create targeted plots to evaluate usefulness of augmentation
- plot accuracy over axis of variation, e.g. day vs. night 

Takeaway: 
- data augmentation -- 

Follow up question for reading group: why don't we see data augmentation that often?
- really learn rather than deal class imbalance? Do you present both images 

So it seems like data augmentation is not for sample size boosting but just to like really refine the model 
